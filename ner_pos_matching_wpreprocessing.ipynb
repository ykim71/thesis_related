{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykim71/thesis_related/blob/main/ner_pos_matching_wpreprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5mOgB83cNL1",
        "outputId": "e477e6d6-e022-421b-d90c-e70ac40aa46f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY3dOHE7c8U5",
        "outputId": "a1ecd342-4b33-4342-c473-d36e5e0ecb4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CrowdTangle/final_data_metrics\n"
          ]
        }
      ],
      "source": [
        "%cd drive/'MyDrive'/CrowdTangle/final_data_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ6Qo4-hAyil"
      },
      "source": [
        "\n",
        "\n",
        "## pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JJGVnyO5qAIg"
      },
      "outputs": [],
      "source": [
        "# import words/phrases from NER and POS tagging\n",
        "import pandas as pd\n",
        "\n",
        "ner_pos = pd.read_excel('pos_bigrams_all_merged_NER4.xlsx')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8uH7DQdDx5UJ"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def bigrams(s):\n",
        "    return [i for i in s if re.search(r'\\s', i) ] \n",
        "def unigrams(s):\n",
        "    return [i for i in s if not re.search(r'\\s', i) ]\n",
        "def hashtag(s):\n",
        "    return [i for i in s if re.search(r'#', i) ]\n",
        "\n",
        "def contain_the(s): # bigrams that make sense with 'the'\n",
        "  to_remove = [' #', '# ', '.','\\'s', \"’s\", \" \\'\", \"\\'\", \"\\'S\", '“', '\"', '’', ]\n",
        "  p = re.compile('|'.join(map(re.escape, to_remove))) # escape to handle metachars\n",
        "  s = [p.sub('', s) for s in s] # remove hashtags\n",
        "\n",
        "  matchers = ['The ', 'the ']\n",
        "  items = [i for i in s if any(xs in i for xs in matchers)]\n",
        "  temp = [i for i in items if i.count(' ')==1]\n",
        "  return list(set(temp))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vlda7fBe_yA3",
        "outputId": "fe15d8ff-da8e-495e-df8f-526be1087a94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2712\n",
            "185\n",
            "181\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "# for Republican words/phrases\n",
        "\n",
        "ner_rep_only = ner_pos.loc[(ner_pos['rep'] == 1)]\n",
        "\n",
        "temp = ner_rep_only['text'].values.tolist()\n",
        "ner_rep_only_list = list(set(temp))\n",
        "print(len(ner_rep_only_list))\n",
        "\n",
        "# bi-grams\n",
        "rep_bi = list(set(bigrams(ner_rep_only_list)))\n",
        "\n",
        "import re\n",
        "\n",
        "to_remove = [' #', '# ', '.','\\'s', \"’s\", \" \\'\", \"\\'\", \"\\'S\", '“', '\"', '’', ' Timeline', ' Photo', 'the ', 'The ']\n",
        "\n",
        "p = re.compile('|'.join(map(re.escape, to_remove))) # escape to handle metachars\n",
        "\n",
        "rep_bi = [p.sub('', s) for s in rep_bi] # remove hashtags\n",
        "\n",
        "rep_bi = list(set(bigrams(rep_bi))) # select only bi-grams (hashtags will be added here)\n",
        "\n",
        "# uni-grams\n",
        "\n",
        "rep_uni = list(set(unigrams(ner_rep_only_list)))\n",
        "print(len(rep_uni))\n",
        "import re\n",
        "\n",
        "to_remove = ['#', '.', '\\'s', \"’s\", \" \\'\", \"\\'\", \"\\'S\", '“', '\"', '’']\n",
        "\n",
        "p = re.compile('|'.join(map(re.escape, to_remove))) # escape to handle metachars\n",
        "\n",
        "rep_uni = [p.sub('', s) for s in rep_uni] # remove some characters\n",
        "rep_uni = list(set(rep_uni))\n",
        "print(len(rep_uni))\n",
        "\n",
        "\n",
        "# hashtags\n",
        "\n",
        "import re\n",
        "\n",
        "rep_hash = list(set(hashtag(ner_rep_only_list)))\n",
        "\n",
        "to_remove = [' #', '# ', '#']\n",
        "p = re.compile('|'.join(map(re.escape, to_remove))) # escape to handle metachars\n",
        "\n",
        "rep_hash = [p.sub('', s) for s in rep_hash] # remove hashtags\n",
        "rep_hash_non = list(set(rep_hash))\n",
        "\n",
        "rep_hash = ['#' + s for s in rep_hash]\n",
        "rep_hash = list(set(rep_hash))\n",
        "\n",
        "# bigrams with the\n",
        "\n",
        "rep_bi_the = contain_the(list(set(bigrams(ner_rep_only_list)))) \n",
        "print(len(rep_bi_the))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "BnYSd2a5o2lG"
      },
      "outputs": [],
      "source": [
        "rep_bi_hashtags = rep_bi + rep_hash + rep_bi_the\n",
        "rep_uni_nonhashtags = rep_uni + rep_hash_non\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjNFi7tl_4YM",
        "outputId": "e5b052e2-ca6f-4711-f4d3-38b720aeadd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2533\n",
            "175\n",
            "173\n"
          ]
        }
      ],
      "source": [
        "# for Democratic words/phrases\n",
        "\n",
        "ner_dem_only = ner_pos.loc[(ner_pos['dem'] == 1)]\n",
        "\n",
        "temp = ner_dem_only['text'].values.tolist()\n",
        "ner_dem_only_list = list(set(temp))\n",
        "print(len(ner_dem_only_list))\n",
        "\n",
        "# bi-grams\n",
        "dem_bi = list(set(bigrams(ner_dem_only_list)))\n",
        "\n",
        "import re\n",
        "\n",
        "to_remove = [' #', '# ', '.','\\'s', \"’s\", \" \\'\", \"\\'\", \"\\'S\", '“', '\"', '’', ' Timeline', ' Photo', 'the ', 'The ']\n",
        "\n",
        "p = re.compile('|'.join(map(re.escape, to_remove))) # escape to handle metachars\n",
        "\n",
        "dem_bi = [p.sub('', s) for s in dem_bi] # remove hashtags\n",
        "\n",
        "dem_bi = list(set(bigrams(dem_bi))) # select only bi-grams (hashtags will be added here)\n",
        "\n",
        "\n",
        "# uni-grams\n",
        "\n",
        "dem_uni = list(set(unigrams(ner_dem_only_list)))\n",
        "print(len(dem_uni))\n",
        "import re\n",
        "\n",
        "to_remove = ['#', '.', '\\'s', \"’s\", \" \\'\", \"\\'\", \"\\'S\", '“', '\"', '’']\n",
        "\n",
        "p = re.compile('|'.join(map(re.escape, to_remove))) # escape to handle metachars\n",
        "\n",
        "dem_uni = [p.sub('', s) for s in dem_uni] # remove some characters\n",
        "dem_uni = list(set(dem_uni))\n",
        "print(len(dem_uni))\n",
        "\n",
        "# hashtags\n",
        "\n",
        "import re\n",
        "\n",
        "dem_hash = list(set(hashtag(ner_dem_only_list)))\n",
        "\n",
        "to_remove = [' #', '# ', '#']\n",
        "p = re.compile('|'.join(map(re.escape, to_remove))) # escape to handle metachars\n",
        "\n",
        "dem_hash = [p.sub('', s) for s in dem_hash] # remove hashtags\n",
        "dem_hash_non = list(set(dem_hash))\n",
        "\n",
        "dem_hash = ['#' + s for s in dem_hash]\n",
        "dem_hash = list(set(dem_hash))\n",
        "\n",
        "\n",
        "# bigrams with the\n",
        "\n",
        "dem_bi_the = contain_the(list(set(bigrams(ner_dem_only_list)))) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "f5fOhkq8qjdy"
      },
      "outputs": [],
      "source": [
        "\n",
        "dem_bi_hashtags = dem_bi + dem_hash + dem_bi_the\n",
        "dem_uni_nonhashtags = dem_uni + dem_hash_non\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "6VMI6eiVIfiE"
      },
      "outputs": [],
      "source": [
        "# make lowercases for matching\n",
        "\n",
        "temp_rep_lower_bi = list( set([x.lower() for x in rep_bi_hashtags] ))\n",
        "temp_dem_lower_bi = list( set([x.lower() for x in dem_bi_hashtags] ))\n",
        "\n",
        "temp_rep_lower_uni = list( set([x.lower() for x in rep_uni_nonhashtags]) )\n",
        "temp_dem_lower_uni = list( set([x.lower() for x in dem_uni_nonhashtags]) )\n",
        "\n",
        "# temp_rep_lower_bi_the = list( set([x.lower() for x in rep_bi_the] ))\n",
        "# temp_dem_lower_bi_the = list( set([x.lower() for x in dem_bi_the] ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WINJl0frMJ74",
        "outputId": "c70d7ec8-82b1-4196-f8b1-c6415dbf40e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2133\n",
            "2059\n",
            "245\n",
            "236\n"
          ]
        }
      ],
      "source": [
        "print(len(temp_rep_lower_bi))\n",
        "print(len(temp_dem_lower_bi))\n",
        "\n",
        "print(len(temp_rep_lower_uni))\n",
        "print(len(temp_dem_lower_uni))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9Zz_169Dp_M"
      },
      "source": [
        "## matching sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8jo4Ag7DtmN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "r_pages_st_sample = pd.read_csv(\"r_pages_st_sample.csv\")\n",
        "d_pages_st_sample = pd.read_csv(\"d_pages_st_sample.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnuwETVUD-zE"
      },
      "outputs": [],
      "source": [
        "d_pages_st_sample['leanings'] = 'democratic'\n",
        "r_pages_st_sample['leanings'] = 'republican'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63YL6LBsEEJJ"
      },
      "outputs": [],
      "source": [
        "sample_df_st = pd.concat([r_pages_st_sample, d_pages_st_sample], ignore_index=True, sort=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQvENY4BD5CH"
      },
      "outputs": [],
      "source": [
        "sample_df_st['text_san'] = sample_df_st['text_san'].str.lower()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPdX_ceLIaJh"
      },
      "outputs": [],
      "source": [
        "\n",
        "sample_df_st['lower_ner_pos_rep_b'] = sample_df_st['text_san'].apply(lambda x: [i for i in temp_rep_lower_bi if i in x])\n",
        "sample_df_st['lower_ner_pos_rep_u'] = sample_df_st['text_san'].apply(lambda x: set.intersection(set(x.split(' ')), temp_rep_lower_uni))\n",
        "\n",
        "sample_df_st['lower_ner_pos_dem_b'] = sample_df_st['text_san'].apply(lambda x: [i for i in temp_dem_lower_bi if i in x])\n",
        "sample_df_st['lower_ner_pos_dem_u'] = sample_df_st['text_san'].apply(lambda x: set.intersection(set(x.split(' ')), temp_dem_lower_uni))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jajy5SiCJVIR"
      },
      "outputs": [],
      "source": [
        "sample_df_st.to_csv('sample_df_st_lower.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53YdolCGA1do"
      },
      "source": [
        "## matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cN-FtLAKq_kX"
      },
      "outputs": [],
      "source": [
        "# for entire posts\n",
        "\n",
        "def basic_sanitize(text):\n",
        "    \n",
        "    text = re.sub(r'[\\'’]',' ', text) #&\n",
        "    text = re.sub(r'[^\\w\\s#&-]','', text) #&\n",
        "    text = text.lower()\n",
        "    \n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### for Republican posts"
      ],
      "metadata": {
        "id": "VG0Rv4luqQiJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvjHCm5z8S98"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('r_pages_ner_pos.pickle', 'rb') as handle:\n",
        "    r_pages_st = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlVH-QbYrDd8"
      },
      "outputs": [],
      "source": [
        "r_pages_st['text_san'] = r_pages_st['text'].apply(basic_sanitize)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkcV3CIhLdVY",
        "outputId": "e5a5042e-d1f4-43d7-de7c-c36147e092b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3030277    waking up   wwwmainwashedcom timeline photos l...\n",
              "6832155     trump signs order to improve mental health re...\n",
              "5330745    look what the intolerant left did to our frien...\n",
              "Name: text_san, dtype: object"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r_pages_st['text_san'].sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FTypxHIsKQL",
        "outputId": "d5ae684c-53d7-42ce-cfdf-2e65c663464c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2132\n",
            "2055\n",
            "246\n",
            "236\n"
          ]
        }
      ],
      "source": [
        "print(len(temp_rep_lower_bi))\n",
        "print(len(temp_dem_lower_bi))\n",
        "\n",
        "print(len(temp_rep_lower_uni))\n",
        "print(len(temp_dem_lower_uni))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Bs8tSXtAmND"
      },
      "outputs": [],
      "source": [
        "# matching\n",
        "\n",
        "r_pages_st['ner_pos_rep_b'] = r_pages_st['text_san'].apply(lambda x: [i for i in temp_rep_lower_bi if i in x])\n",
        "r_pages_st['ner_pos_rep_u'] = r_pages_st['text_san'].apply(lambda x: set.intersection(set(x.split(' ')), temp_rep_lower_uni))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53uYEqM4BID8"
      },
      "outputs": [],
      "source": [
        "r_pages_st['ner_pos_dem_b'] = r_pages_st['text_san'].apply(lambda x: [i for i in temp_dem_lower_bi if i in x])\n",
        "r_pages_st['ner_pos_dem_u'] = r_pages_st['text_san'].apply(lambda x: set.intersection(set(x.split(' ')), temp_dem_lower_uni))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIKtwydBCQ-h"
      },
      "outputs": [],
      "source": [
        "# saving results\n",
        "\n",
        "r_pages_st5 = r_pages_st[['quarter','insult','sentistr','ner_pos_rep_u','ner_pos_rep_b','ner_pos_dem_u','ner_pos_dem_b']]\n",
        "\n",
        "import pickle\n",
        "\n",
        "with open('r_pages_ner_pos_3rd_lowercase.pickle', 'wb') as handle:\n",
        "    pickle.dump(r_pages_st5, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdzjA4eHs82S",
        "outputId": "38967b4e-46eb-4f6a-fc90-d97f8cd943a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "in_group_np\n",
            "non_mentioned    4352731\n",
            "mentioned        2997907\n",
            "Name: in_group_np, dtype: int64\n",
            "out_group_np\n",
            "non_mentioned    4730356\n",
            "mentioned        2620282\n",
            "Name: out_group_np, dtype: int64\n",
            "no_entity_np\n",
            "mentioned    4238245\n",
            "none         3112393\n",
            "Name: no_entity_np, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# print('in_group_np')\n",
        "# print(r_pages_st['in_group_np'].value_counts())\n",
        "\n",
        "# print('out_group_np')\n",
        "# print(r_pages_st['out_group_np'].value_counts())\n",
        "\n",
        "# print('no_entity_np')\n",
        "# print(r_pages_st['no_entity_np'].value_counts())\n",
        "\n",
        "\n",
        "# temp  = r_pages_st.groupby(['quarter', 'out_group_np'])['sentistr_std'].mean().reset_index()\n",
        "# temp.to_csv('pos_ner_lower/r_out_group_np_senti.csv', encoding='utf-8-sig')\n",
        "\n",
        "# temp  = r_pages_st.groupby(['quarter', 'out_group_np'])['insult_std'].mean().reset_index()\n",
        "# temp.to_csv('pos_ner_lower/r_out_group_np_inciv.csv', encoding='utf-8-sig')\n",
        "\n",
        "# temp  = r_pages_st.groupby(['quarter', 'in_group_np'])['sentistr_std'].mean().reset_index()\n",
        "# temp.to_csv('pos_ner_lower/r_in_group_np_senti.csv', encoding='utf-8-sig')\n",
        "\n",
        "# temp  = r_pages_st.groupby(['quarter', 'in_group_np'])['insult_std'].mean().reset_index()\n",
        "# temp.to_csv('pos_ner_lower/r_in_group_np_inciv.csv', encoding='utf-8-sig')\n",
        "\n",
        "# temp  = r_pages_st.groupby(['quarter', 'no_entity_np'])['sentistr_std'].mean().reset_index()\n",
        "# temp.to_csv('pos_ner_lower/r_no_entity_np_senti.csv', encoding='utf-8-sig')\n",
        "\n",
        "# temp  = r_pages_st.groupby(['quarter', 'no_entity_np'])['insult_std'].mean().reset_index()\n",
        "# temp.to_csv('pos_ner_lower/r_no_entity_np_inciv.csv', encoding='utf-8-sig')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mi6ZNtBTaSLS"
      },
      "outputs": [],
      "source": [
        "# manual checking\n",
        "\n",
        "r_pages_st_sample = r_pages_st.sample(1000)\n",
        "r_pages_st_sample.to_csv('r_pages_st_sample_lower.csv', encoding='utf-8-sig')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### for Democratic posts"
      ],
      "metadata": {
        "id": "IaOxSrYlqUQK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "w9GtInP_BL64"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('d_pages_ner_pos.pickle', 'rb') as handle:\n",
        "    d_pages_st = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "jsDVR642tS4D"
      },
      "outputs": [],
      "source": [
        "d_pages_st['text_san'] = d_pages_st['text'].apply(basic_sanitize)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zidU4VSFM8Er",
        "outputId": "e30ea51e-a5f8-42e4-c895-efbe7870bd89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5164760     trump seen golfing at his virginia club over ...\n",
              "1841491     uniteblue we cannot stay silent as this lawle...\n",
              "2170569    what is fuckabee afraid the nsa heard surely h...\n",
              "Name: text_san, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "d_pages_st['text_san'].sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "VGhoBSpCBXkv"
      },
      "outputs": [],
      "source": [
        "\n",
        "d_pages_st['ner_pos_rep_b'] = d_pages_st['text_san'].apply(lambda x: [i for i in temp_rep_lower_bi if i in x])\n",
        "\n",
        "d_pages_st['ner_pos_rep_u'] = d_pages_st['text_san'].apply(lambda x: set.intersection(set(x.split(' ')), temp_rep_lower_uni))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "TAdWhYwZBXgc"
      },
      "outputs": [],
      "source": [
        "d_pages_st['ner_pos_dem_b'] = d_pages_st['text_san'].apply(lambda x: [i for i in temp_dem_lower_bi if i in x])\n",
        "\n",
        "d_pages_st['ner_pos_dem_u'] = d_pages_st['text_san'].apply(lambda x: set.intersection(set(x.split(' ')), temp_dem_lower_uni))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "uWzMt9gttlku"
      },
      "outputs": [],
      "source": [
        "d_pages_st5 = d_pages_st[['quarter','insult','sentistr','ner_pos_rep_u','ner_pos_rep_b','ner_pos_dem_u','ner_pos_dem_b']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "N3wukUiSCUaC"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pickle\n",
        "\n",
        "with open('d_pages_ner_pos_3rd_lowercase.pickle', 'wb') as handle:\n",
        "    pickle.dump(d_pages_st5, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xrjOILGSNP-R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c7d4fd7-a817-4e22-9b96-70121a2fc898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in_group_np\n",
            "non_mentioned    4373991\n",
            "mentioned        2436033\n",
            "Name: in_group_np, dtype: int64\n",
            "out_group_np\n",
            "non_mentioned    3643522\n",
            "mentioned        3166502\n",
            "Name: out_group_np, dtype: int64\n",
            "no_entity_np\n",
            "mentioned    4299352\n",
            "none         2510672\n",
            "Name: no_entity_np, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# print('in_group_np')\n",
        "# print(d_pages_st['in_group_np'].value_counts())\n",
        "\n",
        "# print('out_group_np')\n",
        "# print(d_pages_st['out_group_np'].value_counts())\n",
        "\n",
        "# print('no_entity_np')\n",
        "# print(d_pages_st['no_entity_np'].value_counts())\n",
        "\n",
        "\n",
        "# temp  = d_pages_st.groupby(['quarter', 'out_group_np'])['sentistr_std'].mean().reset_index()\n",
        "# temp.to_csv('pos_ner_lower/d_out_group_np_senti.csv', encoding='utf-8-sig')\n",
        "\n",
        "# temp  = d_pages_st.groupby(['quarter', 'out_group_np'])['insult_std'].mean().reset_index()\n",
        "# temp.to_csv('pos_ner_lower/d_out_group_np_inciv.csv', encoding='utf-8-sig')\n",
        "\n",
        "# temp  = d_pages_st.groupby(['quarter', 'in_group_np'])['sentistr_std'].mean().reset_index()\n",
        "# temp.to_csv('pos_ner_lower/d_in_group_np_senti.csv', encoding='utf-8-sig')\n",
        "\n",
        "# temp  = d_pages_st.groupby(['quarter', 'in_group_np'])['insult_std'].mean().reset_index()\n",
        "# temp.to_csv('pos_ner_lower/d_in_group_np_inciv.csv', encoding='utf-8-sig')\n",
        "\n",
        "# temp  = d_pages_st.groupby(['quarter', 'no_entity_np'])['sentistr_std'].mean().reset_index()\n",
        "# temp.to_csv('pos_ner_lower/d_no_entity_np_senti.csv', encoding='utf-8-sig')\n",
        "\n",
        "# temp  = d_pages_st.groupby(['quarter', 'no_entity_np'])['insult_std'].mean().reset_index()\n",
        "# temp.to_csv('pos_ner_lower/d_no_entity_np_inciv.csv', encoding='utf-8-sig')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWnfUeq-b9_M"
      },
      "outputs": [],
      "source": [
        "# manual checking\n",
        "d_pages_st_sample = d_pages_st.sample(1000)\n",
        "d_pages_st_sample.to_csv('d_pages_st_sample_lower.csv', encoding='utf-8-sig')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcQRUjCmD8C-"
      },
      "source": [
        "## merge results from both leanings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HpIZXwwbD5Cb"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('r_pages_ner_pos_3rd_lowercase.pickle', 'rb') as handle:\n",
        "    r_pages_st = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "w1CpGwn8EP6a"
      },
      "outputs": [],
      "source": [
        "\n",
        "with open('d_pages_ner_pos_3rd_lowercase.pickle', 'rb') as handle:\n",
        "    d_pages_st = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4tajyM2a_kAO"
      },
      "outputs": [],
      "source": [
        "r_pages_st['leanings'] = \"republican\"\n",
        "d_pages_st['leanings'] = \"democratic\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "d_pages_st[['sentistr_std', 'insult_std']] = scaler.fit_transform(d_pages_st[['sentistr', 'insult']])\n",
        "\n",
        "r_pages_st[['sentistr_std', 'insult_std']] = scaler.fit_transform(r_pages_st[['sentistr', 'insult']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcmIvAgdUlyF",
        "outputId": "c98d0092-6998-45f3-9cd3-77f084e6404d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:991: RuntimeWarning: invalid value encountered in subtract\n",
            "  temp = X - T\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:993: RuntimeWarning: invalid value encountered in subtract\n",
            "  X -= self.mean_\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:991: RuntimeWarning: invalid value encountered in subtract\n",
            "  temp = X - T\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:993: RuntimeWarning: invalid value encountered in subtract\n",
            "  X -= self.mean_\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "d_pages_st['ner_pos_dem_b_count'] = d_pages_st['ner_pos_dem_b'].str.len()\n",
        "d_pages_st['ner_pos_dem_u_count'] = d_pages_st['ner_pos_dem_u'].str.len()\n",
        "\n",
        "d_pages_st['ner_pos_rep_b_count'] = d_pages_st['ner_pos_rep_b'].str.len()\n",
        "d_pages_st['ner_pos_rep_u_count'] = d_pages_st['ner_pos_rep_u'].str.len()\n",
        "\n",
        "\n",
        "d_pages_st['out_group_np'] = np.where(( (d_pages_st.ner_pos_rep_u_count >= 1) | (d_pages_st.ner_pos_rep_b_count >= 1) ), 'mentioned', 'non_mentioned')\n",
        "d_pages_st['in_group_np'] = np.where(( (d_pages_st.ner_pos_dem_u_count >= 1) | (d_pages_st.ner_pos_dem_b_count >= 1) ), 'mentioned', 'non_mentioned')\n",
        "d_pages_st['no_entity_np'] = np.where(((d_pages_st.in_group_np == 'non_mentioned') & (d_pages_st.out_group_np == 'non_mentioned')), 'none', 'mentioned')\n"
      ],
      "metadata": {
        "id": "KpEB4CoxCtLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "r_pages_st['ner_pos_dem_b_count'] = r_pages_st['ner_pos_dem_b'].str.len()\n",
        "r_pages_st['ner_pos_dem_u_count'] = r_pages_st['ner_pos_dem_u'].str.len()\n",
        "\n",
        "r_pages_st['ner_pos_rep_b_count'] = r_pages_st['ner_pos_rep_b'].str.len()\n",
        "r_pages_st['ner_pos_rep_u_count'] = r_pages_st['ner_pos_rep_u'].str.len()\n",
        "\n",
        "\n",
        "r_pages_st['in_group_np'] = np.where(( (r_pages_st.ner_pos_rep_u_count >= 1) | (r_pages_st.ner_pos_rep_b_count >= 1) ), 'mentioned', 'non_mentioned')\n",
        "r_pages_st['out_group_np'] = np.where(( (r_pages_st.ner_pos_dem_u_count >= 1) | (r_pages_st.ner_pos_dem_b_count >= 1) ), 'mentioned', 'non_mentioned')\n",
        "r_pages_st['no_entity_np'] = np.where(((r_pages_st.in_group_np == 'non_mentioned') & (r_pages_st.out_group_np == 'non_mentioned')), 'none', 'mentioned')\n"
      ],
      "metadata": {
        "id": "_rwWnfWaCxQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOmkhDzpADLd",
        "outputId": "2a303917-af30-4b59-d748-4ad86065bcf8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['quarter', 'insult', 'sentistr', 'ner_pos_rep_u', 'ner_pos_rep_b',\n",
              "       'ner_pos_dem_u', 'ner_pos_dem_b', 'leanings', 'sentistr_std',\n",
              "       'insult_std'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "d_pages_st.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CI_iygVPAEvo",
        "outputId": "dac6d09b-1535-4cb1-f315-7a15e2b63dfc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['quarter', 'insult', 'sentistr', 'ner_pos_rep_u', 'ner_pos_rep_b',\n",
              "       'ner_pos_dem_u', 'ner_pos_dem_b', 'leanings', 'sentistr_std',\n",
              "       'insult_std'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "r_pages_st.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "08LXvSbT_lwO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "pages_df_st = pd.concat([r_pages_st, d_pages_st], ignore_index=True, sort=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qgfT3ZQH_0VH"
      },
      "outputs": [],
      "source": [
        "# aggregated by all posts\n",
        "\n",
        "temp  = pages_df_st.groupby(['quarter', 'out_group_np'])['sentistr_std'].mean().reset_index()\n",
        "temp.to_csv('pos_ner_lower/all_np_out_group_senti_std.csv', encoding='utf-8-sig')\n",
        "\n",
        "\n",
        "temp  = pages_df_st.groupby(['quarter', 'in_group_np'])['sentistr_std'].mean().reset_index()\n",
        "temp.to_csv('pos_ner_lower/all_np_in_group_senti_std.csv', encoding='utf-8-sig')\n",
        "\n",
        "\n",
        "temp  = pages_df_st.groupby(['quarter', 'no_entity_np'])['sentistr_std'].mean().reset_index()\n",
        "temp.to_csv('pos_ner_lower/all_np_no_entities_senti_std.csv', encoding='utf-8-sig')\n",
        "\n",
        "\n",
        "temp  = pages_df_st.groupby(['quarter', 'out_group_np'])['insult_std'].mean().reset_index()\n",
        "temp.to_csv('pos_ner_lower/all_np_out_group_insult_std.csv', encoding='utf-8-sig')\n",
        "\n",
        "\n",
        "temp  = pages_df_st.groupby(['quarter', 'in_group_np'])['insult_std'].mean().reset_index()\n",
        "temp.to_csv('pos_ner_lower/all_np_in_group_insult_std.csv', encoding='utf-8-sig')\n",
        "\n",
        "\n",
        "temp  = pages_df_st.groupby(['quarter', 'no_entity_np'])['insult_std'].mean().reset_index()\n",
        "temp.to_csv('pos_ner_lower/all_np_no_entities_insult_std.csv', encoding='utf-8-sig')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# aggregated by all posts + by leanings\n",
        "\n",
        "temp  = pages_df_st.groupby(['quarter', 'out_group_np', 'leanings'])['sentistr_std'].mean().reset_index()\n",
        "temp.to_csv('pos_ner_lower/leanings_np_out_group_senti_std.csv', encoding='utf-8-sig')\n",
        "\n",
        "\n",
        "temp  = pages_df_st.groupby(['quarter', 'in_group_np', 'leanings'])['sentistr_std'].mean().reset_index()\n",
        "temp.to_csv('pos_ner_lower/leanings_np_in_group_senti_std.csv', encoding='utf-8-sig')\n",
        "\n",
        "\n",
        "temp  = pages_df_st.groupby(['quarter', 'no_entity_np', 'leanings'])['sentistr_std'].mean().reset_index()\n",
        "temp.to_csv('pos_ner_lower/leanings_np_no_entities_senti_std.csv', encoding='utf-8-sig')\n",
        "\n",
        "\n",
        "temp  = pages_df_st.groupby(['quarter', 'out_group_np', 'leanings'])['insult_std'].mean().reset_index()\n",
        "temp.to_csv('pos_ner_lower/leanings_np_out_group_insult_std.csv', encoding='utf-8-sig')\n",
        "\n",
        "\n",
        "temp  = pages_df_st.groupby(['quarter', 'in_group_np', 'leanings'])['insult_std'].mean().reset_index()\n",
        "temp.to_csv('pos_ner_lower/leanings_np_in_group_insult_std.csv', encoding='utf-8-sig')\n",
        "\n",
        "\n",
        "temp  = pages_df_st.groupby(['quarter', 'no_entity_np', 'leanings'])['insult_std'].mean().reset_index()\n",
        "temp.to_csv('pos_ner_lower/leanings_np_no_entities_insult_std.csv', encoding='utf-8-sig')\n"
      ],
      "metadata": {
        "id": "zV8Sya9ZVR0S"
      },
      "execution_count": 14,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_9Zz_169Dp_M",
        "VG0Rv4luqQiJ"
      ],
      "machine_shape": "hm",
      "name": "ner-pos-matching-wpreprocessing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPfUKU1j7PbxDhghHeWvQaU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}